{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AdaIn.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1D_JqX2TNEoMHutee_ygJnpN9yK64PmTf","authorship_tag":"ABX9TyMAlaj/2+e3ziSuy1Bt6SI5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"u8A_h_oijC0z"},"source":["import tensorflow as tf\n","from tensorflow.keras.applications import vgg19, VGG19\n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from PIL import Image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lRu9xICxi0HR"},"source":["Funzioni di supporto per manipolare le immagini:\n","\n","\n","1.   process_path: conververte l'immagine in un tensore \n","2.   load_img : aggiunge la dimensione per il batch\n","\n"]},{"cell_type":"code","metadata":{"id":"fom4X9YZi-Nl"},"source":["def process_path(file_path):\n","    img = tf.io.read_file(file_path)\n","    img = tf.image.decode_jpeg(img, channels=3) #decodifica un'immagine jpeg in un tensore di uint8\n","    img = tf.cast(img, tf.float32)\n","    return img\n","\n","\n","def load_img(file_path):\n","    img = process_path(file_path)\n","    img = img[tf.newaxis, :] #viene aggiunta la dimensione per il batch\n","    return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQNdGyN9bj9b"},"source":["logDir = 'model' # cartella in cui viene salvato il modello\n","contentImage = load_img(\"/content/sailboat_cropped.jpg\")\n","styleImage = load_img(\"/content/sketch_cropped.png\")\n","outputImage = \"risultato.jpg\"\n","alpha = 1.0 #variabile per controllare il content-style trade-off"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ErWqGwQVwM9a"},"source":["# Architettura del modello\n","Nelle celle suguenti viene creata la struttura **Encode -> AdaIn -> Decode** impiegata per effettuare il trasferimento di stile "]},{"cell_type":"code","metadata":{"id":"9ttjJsSRxYGI"},"source":["class Encoder(tf.keras.models.Model):\n","    def __init__(self, content_layer):\n","        super(Encoder, self).__init__()\n","        vgg = VGG19(include_top=False, weights=\"imagenet\")\n","\n","        self.vgg = tf.keras.Model(\n","            [vgg.input], [vgg.get_layer(content_layer).output]\n","        )\n","        self.vgg.trainable = False\n","\n","    def call(self, inputs):\n","        preprocessed_input = vgg19.preprocess_input(inputs)\n","        return self.vgg(preprocessed_input)\n","\n","#come suggerito dall'articolo nel decoder viene impiegato il reflection padding\n","#per fare si che i bordi dell'immagini rispecchino l'immagine contenuto\n","\n","class ReflectionPadding2D(tf.keras.layers.Layer):\n","    def __init__(self, padding=1, **kwargs):\n","        super(ReflectionPadding2D, self).__init__(**kwargs)\n","        self.padding = padding\n","\n","    def compute_output_shape(self, s):\n","        return s[0], s[1] + 2 * self.padding, s[2] + 2 * self.padding, s[3]\n","\n","    def call(self, x):\n","        return tf.pad(\n","            x,\n","            [\n","                [0, 0],\n","                [self.padding, self.padding],\n","                [self.padding, self.padding],\n","                [0, 0],\n","            ],\n","            \"REFLECT\",\n","        )\n","\n","\n","def decoder():\n","    return tf.keras.Sequential(\n","        [\n","            ReflectionPadding2D(),\n","            Conv2D(256, (3, 3), activation=\"relu\"),\n","            UpSampling2D(size=2),\n","            ReflectionPadding2D(),\n","            Conv2D(256, (3, 3), activation=\"relu\"),\n","            ReflectionPadding2D(),\n","            Conv2D(256, (3, 3), activation=\"relu\"),\n","            ReflectionPadding2D(),\n","            Conv2D(256, (3, 3), activation=\"relu\"),\n","            ReflectionPadding2D(),\n","            Conv2D(128, (3, 3), activation=\"relu\"),\n","            UpSampling2D(size=2),\n","            ReflectionPadding2D(),\n","            Conv2D(128, (3, 3), activation=\"relu\"),\n","            ReflectionPadding2D(),\n","            Conv2D(64, (3, 3), activation=\"relu\"),\n","            UpSampling2D(size=2),\n","            ReflectionPadding2D(),\n","            Conv2D(64, (3, 3), activation=\"relu\"),\n","            ReflectionPadding2D(),\n","            Conv2D(3, (3, 3)),\n","        ]\n","    )\n","\n","#classe principale che racchiude la fase di encode -> AdaIn -> Decode\n","\n","class TransferNet(tf.keras.Model):\n","    def __init__(self, content_layer):\n","        super(TransferNet, self).__init__()\n","        self.encoder = Encoder(content_layer)\n","        self.decoder = decoder()\n","\n","    def encode(self, content_image, style_image, alpha):\n","        content_feat = self.encoder(content_image)\n","        style_feat = self.encoder(style_image)\n","\n","        t = adaptive_instance_normalization(content_feat, style_feat)\n","        t = alpha * t + (1 - alpha) * content_feat\n","        return t\n","\n","    def decode(self, t):\n","        return self.decoder(t)\n","\n","    def call(self, content_image, style_image, alpha=1.0):\n","        t = self.encode(content_image, style_image, alpha)\n","        g_t = self.decode(t)\n","        return g_t\n","\n","\n","def adaptive_instance_normalization(content_feat, style_feat, epsilon=1e-5):\n","    content_mean, content_variance = tf.nn.moments(\n","        content_feat, axes=[1, 2], keepdims=True\n","    )\n","    style_mean, style_variance = tf.nn.moments(\n","        style_feat, axes=[1, 2], keepdims=True\n","    )\n","    style_std = tf.math.sqrt(style_variance + epsilon)\n","\n","    norm_content_feat = tf.nn.batch_normalization(\n","        content_feat,\n","        mean=content_mean,\n","        variance=content_variance,\n","        offset=style_mean,\n","        scale=style_std,\n","        variance_epsilon=epsilon,\n","    )\n","    return norm_content_feat\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8mddCYB94b7j"},"source":["L'encoder contiene i livelli della rete vgg19, fino a \"block4_conv1\" come specificato dall'articolo. Per quanto riguarda i pesi dell'encoder si sono utilizzati quelli gi√† disponibili. I pesi che vengono caricati riguardano solo il Decoder."]},{"cell_type":"code","metadata":{"id":"6RWbXCgN8PIX"},"source":["from google.colab import drive\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/gdrive', force_remount=True)\n","\n","# Location of Zip File\n","drive_path = '/gdrive/MyDrive/arbitrary-style-transfer-master/arbitrary-style-transfer-master/model'\n","local_path = '/content'\n","\n","# Copy the zip file and move it up one level (AKA out of the drive folder)\n","!cp -r '{drive_path}' .\n","\n","# Navigate to the copied file and unzip it quietly\n","os.chdir(local_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8N7b7uF24HMe"},"source":["content_layer = \"block4_conv1\"\n","transformer = TransferNet(content_layer)\n","ckpt = tf.train.Checkpoint(transformer=transformer)\n","ckpt.restore(tf.train.latest_checkpoint(logDir)).expect_partial()\n","stylized_image = transformer(contentImage, styleImage, alpha=alpha)\n","stylized_image = tf.cast( tf.squeeze(stylized_image), tf.uint8 ).numpy()\n","\n","img = Image.fromarray(stylized_image, mode=\"RGB\")\n","img.save(outputImage)"],"execution_count":null,"outputs":[]}]}